{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lire(path):\n",
    "    with open(path, encoding= 'utf-8') as input_stream: #***\n",
    "        return [tokenizer.tokenize(sentence) for sentence in sent_tokenize(input_stream.read())] #***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [] #changez le chemin \n",
    "corpus.extend(lire(\"C:/Users/andre/OneDrive/Bureau/S1_2026_USN/machine_probing_2025/MARKOV/proust/2998-0.txt\"))\n",
    "corpus.extend(lire(\"C:/Users/andre/OneDrive/Bureau/S1_2026_USN/machine_probing_2025/MARKOV/proust/2999-0.txt\"))\n",
    "corpus.extend(lire(\"C:/Users/andre/OneDrive/Bureau/S1_2026_USN/machine_probing_2025/MARKOV/proust/3000-0.txt\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercice 1 : chaîne de Markov de premier ordre (unigrammes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a. Compter les transitions\n",
    "\n",
    "Écrivez une fonction `compter_transitions_unigrammes` qui, étant donné un corpus (séquences de phrases, une phrase étant une séquence de mot), va compter les différentes transitions d'un mot à l'autre dans le corpus.\n",
    "\n",
    "Le résultat prendra la forme d'un dictionnaire à deux niveaux :\n",
    "- Le premier niveau sera le mot précédent\n",
    "- le second niveau sera le comptage du mot courant étant donné le mot précédent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compter_transitions_unigrammes(corpus):\n",
    "    transitions = {}\n",
    "\n",
    "    for phrase in corpus:\n",
    "        prev = \"\"\n",
    "        for token in phrase:\n",
    "            if prev not in transitions:\n",
    "                transitions[prev] = {}\n",
    "            if token not in transitions[prev]: #***\n",
    "                transitions[prev][token] = 0   #***\n",
    "            transitions[prev][token] += 1      #***\n",
    "            prev = token                       #***\n",
    "\n",
    "    return transitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b. Transformer des comptes en probabilité\n",
    "\n",
    "Écrivez une fonction `probabilifier` qui, étant donné des comptes de transitions, transforme ces comptes en probabilité.\n",
    "\n",
    "La somme des probabilités des transitions partant d'un même mot doit sommer à 1 (ou presque 1, les nombres étant petits, des imprécisions peuvent arriver).\n",
    "\n",
    "Par exemple, la somme des transitions partant du mot `Si` doit sommer à 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def probabilifier(comptes_transitions):\n",
    "    for token in comptes_transitions:\n",
    "        total = sum(comptes_transitions[token].values()) #***\n",
    "        for nxt in comptes_transitions[token]:           #***\n",
    "            comptes_transitions[token][nxt] /= total     #***\n",
    "\n",
    "    return comptes_transitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## c. Créer une chaîne de Markov d'ordre 1\n",
    "\n",
    "En utilisant les fonctions précédentes, écrivez une fonction `chaine_markov_unigramme` qui, étant donné un corpus, renvoie une chaîne de Markov d'ordre 1 (probabilités de transitions d'un mot à un autre)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chaine_markov_unigramme(corpus):\n",
    "    transitions = compter_transitions_unigrammes(corpus)\n",
    "\n",
    "    return probabilifier(transitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "markov_chain = chaine_markov_unigramme(corpus) #***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## d. Générer des phrases avec votre chaîne de Markov\n",
    "\n",
    "Écrivez une fonction `generer_unigramme` qui, étant donné un token de départ, va générer une phrase.\n",
    "\n",
    "On considère que nous sommes à la fin d'une phrase dès que l'on atteint une ponctuation forte ('.', '?', '!').\n",
    "\n",
    "Pour générer le prochain mot, on prendra systématiquement le mot le plus probable étant donné le mot précédent.\n",
    "\n",
    "Afin de vérifier le bon fonctionnement de la fonction, vous générerez d'abord une phrase commençant par `Si`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generer_unigramme(markov_chain, start_token):\n",
    "    maximum = NB_MOTS_MAXI\n",
    "    token = start_token\n",
    "    print(token, end=\" \")\n",
    "    prev = token\n",
    "    while token not in ponctuation and maximum > 0: #***\n",
    "        nxt = sorted([x for x in markov_chain[prev].items()], key=lambda x: -x[1]) #***\n",
    "        token = nxt[0][0] #***\n",
    "        prev = token #***\n",
    "        maximum -= 1 #***\n",
    "        print(token, end=\" \") #***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Si vous avez pas , et de la vie , et de la vie , et de la vie , et de la vie , et de la vie , et de la vie , et de la vie , et de la vie , et de la vie , et de la vie , et de la vie , et de la vie , et de la vie , et de la vie , et de la vie , et de la vie , et de la vie , et de la vie , et de la vie , et ******************************\n",
      "Et comme un peu de la vie , et de la vie , et de la vie , et de la vie , et de la vie , et de la vie , et de la vie , et de la vie , et de la vie , et de la vie , et de la vie , et de la vie , et de la vie , et de la vie , et de la vie , et de la vie , et de la vie , et de la vie , et de la vie , et de la ******************************\n"
     ]
    }
   ],
   "source": [
    "generer_unigramme(markov_chain, \"Si\") #*** modifiez la cellule ci-dessus pour n'afficher que 50 mots (là il y en 100 en output)\n",
    "print (30*'*')\n",
    "generer_unigramme(markov_chain, \"Et\") #*** expliquez pourquoi cela marche\n",
    "print (30*'*')\n",
    "generer_unigramme(markov_chain, \"Luc\") #*** expliquez pourquoi cela ne marche pas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## e. Améliorer la génération\n",
    "\n",
    "Comme vous avez pu le constater, la génération est assez... décevante. Pour améliorer la génération automatique, nous allons ajouter un peu d'aléatoire.\n",
    "\n",
    "Modifiez la fonction `generer_unigramme` pour y ajouter un argument `n_best` qui dira de prendre non pas le mot le plus probable, mais un mot au hasard parmi les `n_best` plus probables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generer_unigramme(markov_chain, start_token, n_best=1):\n",
    "    maximum = NB_MOTS_MAXI\n",
    "    token = start_token\n",
    "    print(token, end=\" \")\n",
    "    prev = token\n",
    "    while token not in ponctuation and maximum > 0:\n",
    "        nxt = sorted([x for x in markov_chain[prev].items()], key=lambda x: -x[1])\n",
    "        token = random.choice(nxt[:n_best])[0] #***\n",
    "        prev = token #***\n",
    "        maximum -= 1 #***\n",
    "        print(token, end=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Et comme une fois que je n' était pas , mais qui n' était pas , et de la vie , mais qui n' est pas , et qui n' était plus de l' autre , mais qui n' était pas , et de l' autre , mais je ne me semblait pas , et de l' air d' une autre part , et de l' air d' une autre part , mais qui ne me semblait que je ne me dit que je ne me semblait pas , mais qui ne me semblait pas de la vie , et qui "
     ]
    }
   ],
   "source": [
    "generer_unigramme(markov_chain, \"Et\", 2) #***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Si l' on a pu croire pendant une grande dame à Balbec pour les jeunes qui n' étaient pas que vous a eu de la plus en avait pas la même pas la plus d' être plus de l' avait eu pour le temps . "
     ]
    }
   ],
   "source": [
    "generer_unigramme(markov_chain, \"Si\", 10) #***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercice 2 : chaîne de Markov d'ordre 2 (bigrammes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous avons fini par avoir une génération acceptable, mais elle demeure encore un peu incohérente. Afin d'améliorer la cohérence de la génération des mots, nous allons utiliser un contexte plus grand afin de générer les mots.\n",
    "\n",
    "Reprenez les fonctions précédentes (à part `probabilifier` qui restera la même) afin d'utiliser non pas un mot, mais deux mots en contexte.\n",
    "\n",
    "Si deux mots sont utilisés comme contexte, ils doivent être séparés par une espace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compter_transitions_bigrammes(corpus):\n",
    "    transitions = {}\n",
    "\n",
    "    for phrase in corpus:\n",
    "        prevs = [\"\", \"\"] #***\n",
    "        for token in phrase:\n",
    "            prev = \" \".join(prevs) #***\n",
    "            if prev not in transitions: #***\n",
    "                transitions[prev] = {} #***\n",
    "            if token not in transitions[prev]: #***\n",
    "                transitions[prev][token] = 0 #***\n",
    "            transitions[prev][token] += 1 #***\n",
    "            prevs[0] = prevs[1] #***\n",
    "            prevs[1] = token #***\n",
    "\n",
    "    return transitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chaine_markov_bigramme(corpus):\n",
    "    transitions = compter_transitions_bigrammes(corpus)\n",
    "\n",
    "    return probabilifier(transitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "markov_chain = chaine_markov_bigramme(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_bi(markov_chain, start_token):\n",
    "    maximum = NB_MOTS_MAXI\n",
    "    token = start_token\n",
    "    print(token, end=\" \")\n",
    "    prevs = [\"\", \"\"]\n",
    "    prevs[1] = token\n",
    "    while token not in ponctuation and maximum > 0:\n",
    "        prev = \" \".join(prevs)\n",
    "        nxt = sorted([x for x in markov_chain[prev].items()], key=lambda x: -x[1])\n",
    "        token = nxt[0][0]\n",
    "        prevs[0] = prevs[1]\n",
    "        prevs[1] = token\n",
    "        maximum -= 1\n",
    "        print(token, end=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Si j' avais été sur la plage , nous ne sommes pas accoutumés , le jour où je ne pouvais pas venir , au contraire , l' idée de moi , mais qui ne sont pas les mêmes que font travailler pour elles , et qui , à la fois , et qui , à la fois , et qui , à la fois , et qui , à la fois , et qui , à la fois , et qui , à la fois , et qui , à la fois , et qui , à la fois , et "
     ]
    }
   ],
   "source": [
    "generate_bi(markov_chain, \"Si\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_bi(markov_chain, start_token, n_best=1):\n",
    "    maximum = NB_MOTS_MAXI\n",
    "    token = start_token\n",
    "    print(token, end=\" \")\n",
    "    prevs = [\"\", \"\"]\n",
    "    prevs[1] = token\n",
    "    while token not in ponctuation and maximum > 0:\n",
    "        prev = \" \".join(prevs)\n",
    "        nxt = sorted([x for x in markov_chain[prev].items()], key=lambda x: -x[1])\n",
    "        token = random.choice(nxt[:n_best])[0]\n",
    "        prevs[0] = prevs[1]\n",
    "        prevs[1] = token\n",
    "        maximum -= 1\n",
    "        print(token, end=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Si j' avais été voir des tempêtes que sur un ton d' indifférence qu' on ne le connaît pas , et que j' étais venu chercher dans ses livres , les jours où je n' avais jamais songé qu' il y a une de ces jeunes gens--on en verra qui étaient venus la voir . "
     ]
    }
   ],
   "source": [
    "generate_bi(markov_chain, \"Si\", 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Si je l' eusse reprise , cette heure d' air et en Amérique , ou comme à une soirée musicale qui perdrait de son visage était plus particulièrement câline avec Swann et que la photographie préférée de Swann qu' il était bien entendu ) avec quelle malice il a prononcé à l' entendre parler des tableaux achetés on ne s' y embrouille dans ces cortèges , un homme qui a cherché de toutes , ni d' autre aux femmes , tâchent de les aggraver , plus d' importance pour moi à Gilberte en faisant semblant d' ignorer que vous , Odette "
     ]
    }
   ],
   "source": [
    "generate_bi(markov_chain, \"Si\", 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercice 3 : chaîne de Markov d'ordre arbitraire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous y sommes presque ! Nous commençons à avoir une génération de qualité acceptable.\n",
    "\n",
    "Afin de rendre votre programme plus générique et plus puissant, réécrivez les fonctions précédentes afin qu'elles puissent créer des chaînes de Markov de n'importe quel ordre.\n",
    "\n",
    "L'ordre de la chaîne de Markov devra être rajouté aux fonctions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compter_transitions(corpus, ordre):\n",
    "    transitions = {}\n",
    "\n",
    "    for phrase in corpus:\n",
    "        prevs = [\"\" for _ in range(ordre)] #***\n",
    "        for token in phrase:\n",
    "            prev = \" \".join(prevs) #***\n",
    "            if prev not in transitions:\n",
    "                transitions[prev] = {}\n",
    "            if token not in transitions[prev]:\n",
    "                transitions[prev][token] = 0\n",
    "            transitions[prev][token] += 1\n",
    "            prevs = prevs[1:] #***\n",
    "            prevs.append(token) #***\n",
    "\n",
    "    return transitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chaine_markov(corpus, ordre):\n",
    "    transitions = compter_transitions(corpus, ordre)\n",
    "\n",
    "    return probabilifier(transitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "markov_chain = chaine_markov(corpus, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generer(markov_chain, ordre, start_token): #***\n",
    "    maximum = NB_MOTS_MAXI\n",
    "    token = start_token\n",
    "    print(token, end=\" \")\n",
    "    prevs = [\"\" for _ in range(ordre)]\n",
    "    prevs[-1] = token\n",
    "    while token not in ponctuation and maximum > 0:\n",
    "        prev = \" \".join(prevs)\n",
    "        nxt = sorted([x for x in markov_chain[prev].items()], key=lambda x: -x[1])\n",
    "        token = nxt[0][0]\n",
    "        prevs = prevs[1:]\n",
    "        prevs.append(token)\n",
    "        maximum -= 1\n",
    "        print(token, end=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La personne du reste qui était le plus complètement dupe de l' illusion qui m' abusait ainsi que mes parents , c' était une chose à laquelle j' avais constamment songé , une chose toute en pensées , c' était une chose à laquelle j' avais constamment songé , une chose toute en pensées , c' était une chose à laquelle j' avais constamment songé , une chose toute en pensées , c' était une chose à laquelle j' avais constamment songé , une chose toute en pensées , c' était une chose à laquelle j' avais constamment songé , une "
     ]
    }
   ],
   "source": [
    "generer(markov_chain, 3, \"La\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generer(markov_chain, ordre, start_token, n_best=1):\n",
    "    maximum = NB_MOTS_MAXI\n",
    "    token = start_token\n",
    "    print(token, end=\" \")\n",
    "    prevs = [\"\" for _ in range(ordre)]\n",
    "    prevs[-1] = token\n",
    "    while token not in ponctuation and maximum > 0:\n",
    "        prev = \" \".join(prevs)\n",
    "        nxt = sorted([x for x in markov_chain[prev].items()], key=lambda x: -x[1])\n",
    "        token = random.choice(nxt[:n_best])[0]\n",
    "        prevs = prevs[1:]\n",
    "        prevs.append(token)\n",
    "        maximum -= 1\n",
    "        print(token, end=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Si j' étais monsieur votre père , je ne sais pas si c' est beaucoup ! "
     ]
    }
   ],
   "source": [
    "generer(markov_chain, 3, \"Si\", 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Si les efforts de sincérité et d' émancipation de Saint-Loup ne pouvaient être trouvés que très nobles , à juger par le résultat extérieur , il était fort à craindre qu' elle se contentât de répondre de loin à ses vieux clients un clignement d' œil significatif . "
     ]
    }
   ],
   "source": [
    "generer(markov_chain, 3, \"Si\", 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depuis les débuts d' Elstir , nous avons bien trouvé qu' elle marquait très mal mais nous ne savions pas qu' elle ait ses cheveux comme ça , ça donne mauvais genre . "
     ]
    }
   ],
   "source": [
    "generer(markov_chain, 3, \"Depuis\", 100) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercice 4 : générer plus qu'une seule phrase (bonus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans les exercices précédents, on générait une seule phrase. Afin de compléter votre générateur, il faut à présent lui ajouter la possibilité de générer plusieurs phrases d'affilée !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a. Se souvenir des mots de la phrase précédente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Une limitation à la génération que nous avons faite jusqu'ici est que les phrases sont vues indépendamment les unes des autres. Cela empêche la génération d'un texte plus complet qui serait constitué de plusieurs phrases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Si l' on n' eût distingué deux yeux plus brillants que les autres . "
     ]
    }
   ],
   "source": [
    "generer(markov_chain, 3, \"Si\", 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Si vous aimez les petites oies blanches . "
     ]
    }
   ],
   "source": [
    "generer(markov_chain, 3, \"Si\", 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
